{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Analytics Data Exploration\n",
    "\n",
    "Interactive notebook for exploring the social media product analytics warehouse.\n",
    "\n",
    "**Prerequisites:** Run `python run_pipeline.py` first to generate data and populate the warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Connect to the warehouse\n",
    "conn = duckdb.connect('../data/warehouse/product_analytics.duckdb', read_only=True)\n",
    "print('Connected to warehouse')\n",
    "\n",
    "# Quick overview\n",
    "tables = conn.execute(\"\"\"\n",
    "    SELECT table_name, estimated_size \n",
    "    FROM duckdb_tables() \n",
    "    WHERE schema_name = 'analytics'\n",
    "\"\"\").fetchdf()\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DAU / WAU / MAU Trends\n",
    "\n",
    "The most fundamental product metrics — tracking daily, weekly, and monthly active users across all platforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAU trend with moving averages\n",
    "dau_df = conn.execute(\"\"\"\n",
    "    SELECT\n",
    "        date_key,\n",
    "        SUM(dau) AS dau,\n",
    "        SUM(total_events) AS total_events,\n",
    "        SUM(total_sessions) AS total_sessions\n",
    "    FROM analytics.agg_daily_metrics\n",
    "    GROUP BY date_key\n",
    "    ORDER BY date_key\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "dau_df['dau_7d_ma'] = dau_df['dau'].rolling(7, min_periods=1).mean()\n",
    "dau_df['events_per_dau'] = (dau_df['total_events'] / dau_df['dau']).round(1)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=dau_df['date_key'], y=dau_df['dau'], name='DAU', opacity=0.5))\n",
    "fig.add_trace(go.Scatter(x=dau_df['date_key'], y=dau_df['dau_7d_ma'], name='7-day MA', line=dict(width=3)))\n",
    "fig.update_layout(title='Daily Active Users', template='plotly_dark', height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Platform Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platform-level metrics\n",
    "platform_df = conn.execute(\"\"\"\n",
    "    SELECT\n",
    "        m.platform_key,\n",
    "        p.platform_name,\n",
    "        ROUND(AVG(m.dau)) AS avg_dau,\n",
    "        SUM(m.total_events) AS total_events,\n",
    "        SUM(m.content_creates) AS content_creates,\n",
    "        SUM(m.likes + m.comments + m.shares) AS interactions,\n",
    "        SUM(m.ad_impressions) AS ad_impressions,\n",
    "        SUM(m.ad_clicks) AS ad_clicks,\n",
    "        ROUND(SUM(m.ad_clicks) * 100.0 / NULLIF(SUM(m.ad_impressions), 0), 3) AS ad_ctr\n",
    "    FROM analytics.agg_daily_metrics m\n",
    "    JOIN analytics.dim_platform p ON m.platform_key = p.platform_key\n",
    "    GROUP BY m.platform_key, p.platform_name\n",
    "    ORDER BY avg_dau DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(platform_df.to_string(index=False))\n",
    "\n",
    "colors = {'facebook': '#1877F2', 'instagram': '#E4405F', 'messenger': '#00B2FF', \n",
    "          'whatsapp': '#25D366', 'threads': '#000000'}\n",
    "\n",
    "fig = px.bar(platform_df, x='platform_name', y='avg_dau', \n",
    "             color='platform_key', color_discrete_map=colors,\n",
    "             title='Average DAU by Platform')\n",
    "fig.update_layout(template='plotly_dark', showlegend=False, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Engagement Funnel Analysis\n",
    "\n",
    "Tracking the conversion funnel from passive viewing to active content creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engagement funnel (latest date)\n",
    "latest_date = conn.execute(\"SELECT MAX(date_key) FROM analytics.fct_events\").fetchone()[0]\n",
    "\n",
    "funnel_df = conn.execute(f\"\"\"\n",
    "    SELECT\n",
    "        COUNT(DISTINCT CASE WHEN event_type_key = 'content_view' THEN user_key END) AS viewers,\n",
    "        COUNT(DISTINCT CASE WHEN event_type_key = 'like' THEN user_key END) AS likers,\n",
    "        COUNT(DISTINCT CASE WHEN event_type_key = 'comment' THEN user_key END) AS commenters,\n",
    "        COUNT(DISTINCT CASE WHEN event_type_key = 'share' THEN user_key END) AS sharers,\n",
    "        COUNT(DISTINCT CASE WHEN event_type_key = 'content_create' THEN user_key END) AS creators\n",
    "    FROM analytics.fct_events\n",
    "    WHERE date_key = DATE '{latest_date}'\n",
    "\"\"\").fetchone()\n",
    "\n",
    "stages = ['View Content', 'Like', 'Comment', 'Share', 'Create Content']\n",
    "values = list(funnel_df)\n",
    "\n",
    "fig = go.Figure(go.Funnel(\n",
    "    y=stages, x=values,\n",
    "    textinfo='value+percent initial',\n",
    "    marker=dict(color=['#1877F2', '#E4405F', '#25D366', '#00B2FF', '#FF6900'])\n",
    "))\n",
    "fig.update_layout(title=f'Engagement Funnel — {latest_date}', template='plotly_dark', height=400)\n",
    "fig.show()\n",
    "\n",
    "# Print conversion rates\n",
    "print(f\"View → Like:    {values[1]/values[0]*100:.1f}%\")\n",
    "print(f\"View → Comment: {values[2]/values[0]*100:.1f}%\")\n",
    "print(f\"View → Share:   {values[3]/values[0]*100:.1f}%\")\n",
    "print(f\"View → Create:  {values[4]/values[0]*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross-Platform Usage Analysis\n",
    "\n",
    "Understanding how users engage across the family of apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_platform = conn.execute(\"\"\"\n",
    "    WITH user_platforms AS (\n",
    "        SELECT user_key, COUNT(DISTINCT platform_key) AS platforms_used\n",
    "        FROM analytics.fct_events\n",
    "        GROUP BY user_key\n",
    "    )\n",
    "    SELECT\n",
    "        platforms_used,\n",
    "        COUNT(*) AS num_users,\n",
    "        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 1) AS pct\n",
    "    FROM user_platforms\n",
    "    GROUP BY platforms_used\n",
    "    ORDER BY platforms_used\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig = px.bar(cross_platform, x='platforms_used', y='num_users',\n",
    "             text='pct', title='Number of Platforms Used per User')\n",
    "fig.update_traces(texttemplate='%{text}%', textposition='outside')\n",
    "fig.update_layout(template='plotly_dark', height=400,\n",
    "                  xaxis_title='Platforms Used', yaxis_title='Number of Users')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Power User Analysis (Pareto)\n",
    "\n",
    "How concentrated is engagement among top users?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power = conn.execute(\"\"\"\n",
    "    WITH user_events AS (\n",
    "        SELECT user_key, COUNT(*) AS total_events,\n",
    "               PERCENT_RANK() OVER (ORDER BY COUNT(*) DESC) AS pct_rank\n",
    "        FROM analytics.fct_events\n",
    "        GROUP BY user_key\n",
    "    )\n",
    "    SELECT\n",
    "        CASE\n",
    "            WHEN pct_rank <= 0.01 THEN 'Top 1%'\n",
    "            WHEN pct_rank <= 0.05 THEN 'Top 5%'\n",
    "            WHEN pct_rank <= 0.10 THEN 'Top 10%'\n",
    "            WHEN pct_rank <= 0.20 THEN 'Top 20%'\n",
    "            WHEN pct_rank <= 0.50 THEN 'Top 50%'\n",
    "            ELSE 'Bottom 50%'\n",
    "        END AS tier,\n",
    "        COUNT(*) AS users,\n",
    "        SUM(total_events) AS events,\n",
    "        ROUND(SUM(total_events) * 100.0 / (SELECT SUM(total_events) FROM user_events), 1) AS pct_events\n",
    "    FROM user_events\n",
    "    GROUP BY tier\n",
    "    ORDER BY MIN(pct_rank)\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(power.to_string(index=False))\n",
    "\n",
    "fig = px.bar(power, x='tier', y='pct_events', text='pct_events',\n",
    "             title='Event Concentration by User Tier (Pareto Analysis)')\n",
    "fig.update_traces(texttemplate='%{text}%', textposition='outside')\n",
    "fig.update_layout(template='plotly_dark', height=400,\n",
    "                  xaxis_title='User Tier', yaxis_title='% of Total Events')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. User Retention Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analytics.retention import RetentionAnalytics\n",
    "\n",
    "ra = RetentionAnalytics(conn)\n",
    "\n",
    "# D1, D3, D7 retention by user segment\n",
    "for n in [1, 3, 7]:\n",
    "    ret = ra.get_retention_by_segment(day_n=n)\n",
    "    print(f\"\\n=== D{n} Retention by Segment ===\")\n",
    "    print(ret.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn risk analysis\n",
    "churn = ra.get_churn_risk_features()\n",
    "\n",
    "risk_dist = churn['churn_risk'].value_counts().reset_index()\n",
    "risk_dist.columns = ['risk_level', 'count']\n",
    "\n",
    "fig = px.pie(risk_dist, values='count', names='risk_level',\n",
    "             title='User Churn Risk Distribution',\n",
    "             color_discrete_sequence=['#25D366', '#FFD700', '#FF6900', '#E4405F'])\n",
    "fig.update_layout(template='plotly_dark', height=400)\n",
    "fig.show()\n",
    "\n",
    "print(f\"\\nChurn Risk Summary:\")\n",
    "print(risk_dist.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Growth Accounting\n",
    "\n",
    "Understanding DAU composition: new vs. retained vs. resurrected users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_df = conn.execute(\"\"\"\n",
    "    WITH daily_active AS (\n",
    "        SELECT DISTINCT user_key, date_key\n",
    "        FROM analytics.fct_events\n",
    "    ),\n",
    "    classified AS (\n",
    "        SELECT\n",
    "            curr.date_key,\n",
    "            curr.user_key,\n",
    "            CASE\n",
    "                WHEN u.signup_date = curr.date_key THEN 'New'\n",
    "                WHEN prev.user_key IS NOT NULL THEN 'Retained'\n",
    "                ELSE 'Resurrected'\n",
    "            END AS user_type\n",
    "        FROM daily_active curr\n",
    "        LEFT JOIN daily_active prev\n",
    "            ON curr.user_key = prev.user_key\n",
    "           AND prev.date_key = curr.date_key - INTERVAL '1 day'\n",
    "        JOIN analytics.dim_users u\n",
    "            ON curr.user_key = u.user_key AND u.is_current = TRUE\n",
    "    )\n",
    "    SELECT date_key, user_type, COUNT(DISTINCT user_key) AS users\n",
    "    FROM classified\n",
    "    GROUP BY date_key, user_type\n",
    "    ORDER BY date_key\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig = px.area(growth_df, x='date_key', y='users', color='user_type',\n",
    "              color_discrete_map={'New': '#25D366', 'Retained': '#1877F2', 'Resurrected': '#FF6900'},\n",
    "              title='Growth Accounting — DAU Composition')\n",
    "fig.update_layout(template='plotly_dark', height=450)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Geographic & Demographic Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic distribution\n",
    "geo_df = conn.execute(\"\"\"\n",
    "    SELECT country, COUNT(DISTINCT user_key) AS users, COUNT(*) AS events\n",
    "    FROM analytics.fct_events\n",
    "    GROUP BY country\n",
    "    ORDER BY users DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig = go.Figure(go.Choropleth(\n",
    "    locations=geo_df['country'], z=geo_df['users'],\n",
    "    locationmode='ISO-3', colorscale='Blues', colorbar_title='Users'\n",
    "))\n",
    "fig.update_layout(title='User Distribution by Country',\n",
    "                  template='plotly_dark', height=450,\n",
    "                  geo=dict(showframe=False, projection_type='natural earth'))\n",
    "fig.show()\n",
    "\n",
    "# Top 10 countries\n",
    "print(\"Top 10 Countries by Users:\")\n",
    "print(geo_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age group and device breakdown\n",
    "demo_df = conn.execute(f\"\"\"\n",
    "    SELECT\n",
    "        u.age_group,\n",
    "        u.device_type,\n",
    "        COUNT(DISTINCT f.user_key) AS users,\n",
    "        COUNT(*) AS events\n",
    "    FROM analytics.fct_events f\n",
    "    JOIN analytics.dim_users u ON f.user_key = u.user_key AND u.is_current = TRUE\n",
    "    WHERE f.date_key = DATE '{latest_date}'\n",
    "    GROUP BY u.age_group, u.device_type\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig = px.treemap(demo_df, path=['age_group', 'device_type'], values='users',\n",
    "                 title=f'User Distribution: Age Group × Device Type ({latest_date})')\n",
    "fig.update_layout(template='plotly_dark', height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Data Quality Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_quality.checks import DataQualityChecker\n",
    "\n",
    "dq = DataQualityChecker(conn)\n",
    "results = dq.run_all_checks()\n",
    "\n",
    "print(f\"\\nData Quality Report\")\n",
    "print(f\"===================\")\n",
    "print(f\"Total checks:  {results['total_checks']}\")\n",
    "print(f\"Passed:        {results['passed']}\")\n",
    "print(f\"Failed:        {results['failed']}\")\n",
    "print(f\"Pass rate:     {results['pass_rate']}\")\n",
    "\n",
    "# Show any failures\n",
    "failures = [d for d in results['details'] if d['status'] == 'failed']\n",
    "if failures:\n",
    "    print(f\"\\nFailed checks:\")\n",
    "    for f in failures:\n",
    "        print(f\"  - [{f['severity']}] {f['check']}: {f['message']}\")\n",
    "else:\n",
    "    print(\"\\nAll checks passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "print('Warehouse connection closed.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
